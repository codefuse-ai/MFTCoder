# MFTCoderè®­ç»ƒ: Atorchæ¡†æ¶ç¯‡
[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/codefuse-ai)
<a href="https://github.com/codefuse-ai/MFTCoder/blob/main/LICENSE">
    <img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue">
</a>

[**ä¸­æ–‡**] [[English]](README.md)

## 1. æ›´æ–°

ğŸ”¥ MFTCoderåœ¨Atorchæ¡†æ¶ä¸‹æ”¯æŒGPTNeoXæ¨¡å‹çš„å¾®è°ƒï¼›

ğŸ”¥ MFTCoderæ”¯æŒå…¨é‡çš„æœ‰ç›‘ç£å¾®è°ƒï¼›

ğŸ”¥ MFTCoderæ”¯æŒLoRAå¾®è°ƒï¼›

## 2. æ•°æ®æ ¼å¼

### 2.1 è®­ç»ƒæ•°æ®æ ¼å¼
è®­ç»ƒæ•°æ®ä¸ºjsonlæ ¼å¼ï¼Œæ¯ä¸€è¡Œçš„æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼Œå…¶ä¸­chat_roundså­—æ®µæ˜¯å¿…éœ€çš„ï¼Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ æˆ–åˆ é™¤å…¶ä»–å­—æ®µã€‚
å¯ä»¥å‚è€ƒé¡¹ç›®ä¸­çš„xxx.jsonlæ–‡ä»¶ã€‚
```json
{
    "id":0,
    "data_name":"code-helper",
    "chat_rounds":[
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»£ç åŠ©æ‰‹ï¼Œå¯ä»¥å›å¤ç”¨æˆ·ä¸ä»£ç ç›¸å…³çš„é—®é¢˜",
            "chat_round_id": 0
        },
        {
            "role": "human",
            "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åº", 
            "chat_round_id": 1
        },
        {
            "role": "bot",
            "content": "ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•xxxxxx", 
            "chat_round_id": 1
        },
        {
            "role": "human",
            "content": "è§£é‡Šä¸€ä¸‹è¿™æ®µä»£ç ", 
            "chat_round_id": 2
        },
        {
            "role": "bot",
            "content": "å¥½çš„ï¼Œè¿™æ®µä»£ç xxx", 
            "chat_round_id": 2
        }
    ]
}
```

### 2.2 æ¨ç†æ•°æ®æ ¼å¼
æ¨ç†æ•°æ®æ ¼å¼ä¸ºæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®æ ¼å¼ä¸‹æ‹¼æ¥çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œå®ƒä¹Ÿæ˜¯æ¨ç†æ—¶è¾“å…¥promptæ‹¼æ¥çš„æ–¹å¼ï¼š
```python
"""
<|role_start|>system<|role_end|>è¿™æ˜¯SystemæŒ‡ä»¤
<|role_start|>human<|role_end|>è¿™æ˜¯ç¬¬1è½®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
<|role_start|>bot<|role_end|>è¿™æ˜¯ç¬¬1è½®æ¨¡å‹ç”Ÿæˆçš„å†…å®¹</s>
<|role_start|>human<|role_end|>è¿™æ˜¯ç¬¬2è½®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
<|role_start|>bot<|role_end|>è¿™æ˜¯ç¬¬2è½®æ¨¡å‹ç”Ÿæˆçš„å†…å®¹</s>
...
...
...
<|role_start|>human<|role_end|>è¿™æ˜¯ç¬¬nè½®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
<|role_start|>bot<|role_end|>{æ¨¡å‹ç°åœ¨è¦ç”Ÿæˆçš„å†…å®¹}</s>
"""
```


## 3. æ¨¡å‹è®­ç»ƒ
ç›®å‰ "MFTCoder/mft_atorch" ä»£ç åº“æ”¯æŒå…¨é‡å‚æ•°æŒ‡ä»¤å¾®è°ƒå’ŒLoRAæŒ‡ä»¤å¾®è°ƒã€‚
ç›®å‰ä»…æ”¯æŒGPTNeoXæ¨¡å‹çš„è®­ç»ƒï¼Œç†è®ºä¸Šï¼ŒHuggingFaceä¸Šå¼€æºçš„GPTNeoXæ¨¡å‹æƒé‡ï¼Œå‡å¯ä½¿ç”¨æœ¬é¡¹ç›®è¿›è¡Œè®­ç»ƒã€‚

æˆ‘ä»¬å°†è®­ç»ƒä¸­ä½¿ç”¨çš„å„ç§ç»„ä»¶æŠ½å–å‡ºæ¥ï¼Œä»¥ä¾¿åç»­çš„æ‰©å±•å’Œä¼˜åŒ–ï¼Œè¯¦è§ä¸»ç›®å½•ä¸‹çš„å®ç°ã€‚å¾®è°ƒè®­ç»ƒçš„å…¥å£ç›®å½•æ˜¯```train/```, è®­ç»ƒå…¥å£æ–‡ä»¶æ˜¯```train/run_train.py```, å‚æ•°é…ç½®å­˜å‚¨åœ¨å¯åŠ¨è„šæœ¬```train/run_gpt_*.sh```ç­‰æ–‡ä»¶ä¸­ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†å’Œæ›´æ”¹ã€‚

### 3.1 æ•°æ®æ ¼å¼
è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†å¤šè½®å¯¹è¯æ‹¼æ¥æˆå¦‚ä¸‹æ ¼å¼ï¼Œç„¶åè¿›è¡Œtokenizeã€‚å…¶ä¸­<|role_start|>human<|role_end|>è¡¨ç¤ºhumanè¾“å…¥æç¤ºç¬¦ï¼Œ<|role_start|>bot<|role_end|>è¡¨ç¤ºbotè¾“å‡ºæç¤ºç¬¦ï¼Œ`````</s>````` è¡¨ç¤ºeos_tokenã€‚
```
"<|role_start|>human<|role_end|>input1</s>target1</s>input2</s>target2</s>...
```
åœ¨è®¡ç®—lossæ—¶ï¼Œæˆ‘ä»¬é€šè¿‡maskçš„æ–¹å¼ï¼Œinputéƒ¨åˆ†çš„lossä¸å‚ä¸å‚æ•°æ›´æ–°ï¼Œåªæœ‰â€œtarget</s>â€éƒ¨åˆ†çš„losså‚ä¸å‚æ•°æ›´æ–°ã€‚
è¿™ç§æ–¹å¼å……åˆ†åˆ©ç”¨äº†æ¨¡å‹å¹¶è¡Œè®¡ç®—çš„ä¼˜åŠ¿ï¼Œè®­ç»ƒæ›´åŠ é«˜æ•ˆï¼Œä¸”å¤šè½®å¯¹è¯ä¸­çš„æ¯ä¸ªtargetéƒ¨åˆ†éƒ½å‚ä¸äº†è®­ç»ƒï¼Œè®­ç»ƒæ›´å……åˆ†ã€‚
å¦åˆ™ï¼Œå°±éœ€è¦æŠŠä¸€ä¸ªnè½®å¯¹è¯ï¼Œæ‹†åˆ†æˆnæ¡æ•°æ®ï¼Œä¸”åªè®¡ç®—æœ€åä¸€ä¸ªtargetçš„lossï¼Œå¤§å¤§é™ä½äº†è®­ç»ƒæ•ˆç‡ã€‚

### 3.2 å…¨é‡SFT

æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯è¿›è¡Œå…¨é‡SFTï¼š
```bash
sh run_gpt_mft.sh 10 1 8 5
```

éœ€æ³¨æ„ï¼Œå¯åŠ¨è„šæœ¬åçš„å››ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯ï¼š
- ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ€»çš„per gpu batch size
- ç¬¬äºŒä¸ªå‚æ•°æ˜¯tensor parallelæ•°ï¼ˆæš‚æ—¶åªæ”¯æŒ1ï¼‰
- ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯data parallelæ•°ï¼Œä¸æ‰€ç”¨GPUæ•°ä¿æŒä¸€è‡´
- ç¬¬å››ä¸ªå‚æ•°æ˜¯è®­ç»ƒepochæ•°

åé¢å…¶ä»–çš„è®­ç»ƒæ–¹å¼å¯åŠ¨è„šæœ¬ï¼Œä¹ŸåŒæ ·éœ€è¦é…ç½®è¿™å››ä¸ªå‚æ•°

### 3.3 LoRAå¾®è°ƒ

æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯è¿›è¡ŒLoraå¾®è°ƒï¼š
```bash
sh run_gpt_mft_peft.sh 10 1 8 5
```

### 3.4 å¯åŠ¨è„šæœ¬ä¸­ä¸»è¦å‚æ•°è¯´æ˜
```train/run_gpt_*.sh```ä¸­çš„ä¸»è¦å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼Œä»¥ä¸‹å‚æ•°å¯ä»¥æ ¹æ®éœ€æ±‚è¿›è¡Œä¿®æ”¹ï¼Œå…¶ä»–å‚æ•°å»ºè®®ä¸åšä¿®æ”¹ï¼š
- tokenize_mode: ç›®å‰ä»…æ”¯æŒ"sft"ã€‚

- train_mode: ç›®å‰ä»…æ”¯æŒ"sft"ã€‚

- load_raw_dataset: éœ€è¦ä¿æŒ"True"ï¼Œåç»­ä¼šæ”¯æŒå…¶å®ƒæ¨¡å¼æ•°æ®ï¼Œå½“å‰ä»…æ”¯æŒjsonlè¾“å…¥

- data_paths: "[path1,path2,path3]" è¾“å…¥æ•°æ®åœ°å€ï¼Œå­—ç¬¦ä¸²ï¼Œå¼€å¤´ç»“å°¾ç”¨[]ï¼Œä¸­é—´ç”¨```,```é—´éš”ä¸åŒpathï¼Œæ¯ä¸ªpathæ˜¯ä¸€ä¸ªç›®å½•ï¼Œç›®å½•çš„æœ€åä¸€çº§åå­—ä½œä¸ºä»»åŠ¡åç§°ï¼Œä¸‹é¢åŒ…å«1åˆ°å¤šä¸ªjsonlæ•°æ®ã€‚

- output_dir: è®­ç»ƒè¾“å‡ºç›®å½•ï¼Œå­˜å‚¨checkpointã€lora_adaptor checkpointç­‰ã€‚

- tensorboard_dir: å¯ä»¥æš‚æ—¶å¿½ç•¥ï¼Œå®é™…tensorboardå­˜å‚¨åœ¨output_dirçš„runsç›®å½•ä¸‹ã€‚

- model_type: ç›®å‰ä»…æ”¯æŒ gpt_neoxã€‚

- peft_type: ç›®å‰ä»…æ”¯æŒ loraã€‚

- pretrained_model_path: é¢„è®­ç»ƒæ¨¡å‹çš„æœ¬åœ°ç›®å½•ã€‚

- total_train_batch_size: æ‰€æœ‰æ˜¾å¡trainçš„batch sizeçš„æ€»å’Œï¼Œä¼šæ ¹æ®å¯åŠ¨è„šæœ¬æ—¶è¾“å…¥çš„per gpu batch sizeè‡ªåŠ¨è®¡ç®—ã€‚

- per_device_valid_batch_size: æ¯å¼ æ˜¾å¡evalçš„batch sizeï¼Œä¼šæ ¹æ®å¯åŠ¨è„šæœ¬æ—¶è¾“å…¥çš„per gpu batch sizeè‡ªåŠ¨è®¡ç®—ã€‚

- gradient_accumulation_steps: æ¢¯åº¦ç´¯è®¡æ­¥æ•°ã€‚global batch=num_gpus * per_device_train_batch_size * gradient_accumulation_stepsã€‚

- checkpoint_activations: å¦‚æœæ˜¾å­˜æ‰è¥Ÿè§è‚˜ï¼Œå¯ä»¥å¼€å¯ã€‚ä»¥æ—¶é—´æ¢ç©ºé—´ï¼Œæ¨¡å‹ä¸ç¼“å­˜æ¿€æ´»çŠ¶æ€ï¼Œä¼šè¿›è¡Œä¸¤æ¬¡forwardè®¡ç®—ï¼Œä»¥èŠ‚çœæ˜¾å­˜ã€‚

- learning_rate: å­¦ä¹ ç‡ã€‚å…¨é‡å‚æ•°å¾®è°ƒçš„æ—¶å€™ï¼Œå»ºè®®å°ä¸€äº›ï¼Œ1e-5æˆ–5e-6ã€‚qloraä¸­çš„å­¦ä¹ ç‡è®¾ç½®æ›´å¤§ä¸€äº›ï¼Œä¸€èˆ¬ä¸º1e-4ã€2e-4ã€‚

- min_lr: æœ€ä½å­¦ä¹ ç‡ï¼Œ ä¸€èˆ¬æ˜¯learning_rateçš„ååˆ†ä¹‹ä¸€ã€‚

- seq_length: è®­ç»ƒæ—¶çš„æœ€å¤§é•¿åº¦ã€‚æŒ‰ç…§è‡ªå·±çš„è®¾å¤‡è¿›è¡Œè®¾ç½®ï¼Œè¶Šé•¿éœ€è¦å ç”¨è¶Šå¤šæ˜¾å­˜ã€‚

- log_interval: æ¯éš”å¤šå°‘æ­¥ç»Ÿè®¡ä¸€æ¬¡train lossã€‚

- checkpointing_steps: æ¯éš”å¤šå°‘æ­¥ä¿å­˜ä¸€ä¸ªæ¨¡å‹ã€‚

- evalation_steps: æ¯éš”å¤šå°‘æ­¥åœ¨éªŒè¯é›†ä¸Ševaluateä¸€æ¬¡ã€‚

- early_stopping_patience: å¤šå°‘ä¸ªeval pointä¸ç»§ç»­æ”¶æ•›ï¼Œåˆ™åœæ­¢è®­ç»ƒã€‚

- lr_scheduler_type: å­¦ä¹ ç‡å˜åŒ–ç­–ç•¥ã€‚

- num_warmup_steps: warm upæ­¥æ•°ï¼Œå­¦ä¹ ç‡ç»è¿‡å¤šå°‘æ­¥ï¼Œå¢é•¿åˆ°æŒ‡å®šçš„æ•°å€¼ã€‚

- seed: éšæœºç§å­ï¼Œç”¨äºå¤ç°å®éªŒç»“æœã€‚

- train_iters: å¯ä»¥æš‚æ—¶è®¾ä¸ºæ¯”è¾ƒå°çš„æ•°ï¼Œå¦‚10ï¼Œå®é™…ä¸Šä¸ä¼šå½±å“è®­ç»ƒæ­¥æ•°ï¼Œç•™ä½œåé¢æ‹“å±•è¯»å–å…¶ä»–å½¢å¼æ•°æ®é›†çš„åŠŸèƒ½ã€‚

- valid_iters: å¯ä»¥æš‚æ—¶è®¾ä¸ºæ¯”è¾ƒå°çš„æ•°ï¼Œå¦‚10ï¼Œå®é™…ä¸Šä¸ä¼šå½±å“è®­ç»ƒæ­¥æ•°ï¼Œç•™ä½œåé¢æ‹“å±•è¯»å–å…¶ä»–å½¢å¼æ•°æ®é›†çš„åŠŸèƒ½ã€‚

- evaluation_strategy: è®­ç»ƒæœŸé—´evaluateçš„ç­–ç•¥ï¼Œ"steps"è¡¨ç¤ºæ¯éš”"valid_interval"æ­¥åšä¸€æ¬¡evaluateï¼Œ"epoch"è¡¨ç¤ºæ¯éš”ä¸€ä¸ªepochåšä¸€æ¬¡evaluateï¼Œæ”¯æŒåŒæ—¶å¼€å¯ã€‚

- save_strategy: è®­ç»ƒæœŸé—´ä¿å­˜æ¨¡å‹æƒé‡çš„ç­–ç•¥ï¼Œ"steps"è¡¨ç¤ºæ¯éš”"checkpointing_steps"æ­¥ä¿å­˜ä¸€æ¬¡ã€‚

- extra_save_by_epoch: æ¯è¿‡ä¸€ä¸ªepochæ˜¯å¦è¦ä¿å­˜ä¸€ä¸ªepochçº§åˆ«çš„checkpointã€‚

- save_total_limit: æœ€å¤šä¿ç•™çš„æ¨¡å‹checkpointä¸ªæ•°ï¼Œä¸€èˆ¬è®¾ç½®ä¸º2ï¼Œä¼šä¿ç•™valid lossæœ€ä½ï¼Œä»¥åŠæœ€æ–°çš„checkpointï¼Œæ³¨æ„epochçº§åˆ«çš„checkpointä¼šä¸€ç›´ä¿ç•™ï¼Œä¸”ä¸å—é™åˆ¶ã€‚

- weighted_loss_mode: å¤šä»»åŠ¡è®­ç»ƒçš„lossåŠ æƒæ–¹å¼ã€‚


## 4. æ¨¡å‹ä½¿ç”¨

### 4.1 æƒé‡åˆå¹¶
å¦‚æœä½¿ç”¨LoRAè¿›è¡Œè®­ç»ƒï¼Œæœ¬é¡¹ç›®ä»…ä¿å­˜adapterçš„æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œéœ€è¦å°†adapteræƒé‡ä¸base modelè¿›è¡Œåˆå¹¶ã€‚è„šæœ¬è§```utils/merge_base_and_lora_to_hf.py```

### 4.2 æ¨¡å‹æ¨ç†
æˆ‘ä»¬æä¾›äº†å•è½®å¯¹è¯å’Œå¤šè½®å¯¹è¯çš„å¦‚ä¸‹è„šæœ¬ï¼Œè¯¥è„šæœ¬å¯åŒæ—¶å…¼å®¹å¤§éƒ¨åˆ†huggingfaceæ ¼å¼çš„æ¨¡å‹ã€‚
```python
from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM,
)
tokenizer = AutoTokenizer.from_pretrained(mode_name_or_path, trust_remote_code=True, use_fast=False, legacy=False)
tokenizer.padding_side = "left"
tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids("<unk>")
tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids("</s>")
model = AutoModelForCausalLM.from_pretrained(mode_name_or_path, trust_remote_code=True)

HUMAN_ROLE_START_TAG = "<|role_start|>human<|role_end|>"
BOT_ROLE_START_TAG = "<|role_start|>bot<|role_end|>"
texts = ["write a python function of quick sort."]
texts = [f"{HUMAN_ROLE_START_TAG}{text}{BOT_ROLE_START_TAG}" for text in texts]

inputs = tokenizer(texts, return_tensors='pt', padding=True, add_special_tokens=False).to("cuda")
outputs = model.generate(
        inputs=inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        max_new_tokens=512,
        top_p=0.95,
        temperature=0.1,
        do_sample=True,
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.pad_token_id
    )
gen_text = tokenizer.batch_decode(outputs[:, inputs["input_ids"].shape[1]:], skip_special_tokens=True)
print(gen_text)
```

ç”Ÿæˆè„šæœ¬ä¸­çš„top_pã€temperatureã€repetition_penaltyã€do_sampleç­‰å‚æ•°å¯¹æ¨¡å‹çš„ç”Ÿæˆæ•ˆæœå½±å“è¾ƒå¤§ï¼Œå¯æŒ‰ç…§è‡ªå·±çš„ä½¿ç”¨åœºæ™¯è¿›è¡Œè°ƒè¯•ä¿®æ”¹ã€‚
å®è·µä¸­ï¼Œåœ¨ä»£ç ç”Ÿæˆåœºæ™¯ä¸­ï¼Œå¦‚æœé‡‡æ ·æ¨¡å¼ï¼Œdo_sample=True, top_p=0.95, temperature=0.1æ˜¯pass@1æŒ‡æ ‡çš„ä¸é”™é€‰æ‹©ï¼›
å¦‚æœéé‡‡æ ·æ¨¡å¼ï¼Œ do_sample=False, beam_num=1æˆ–è€…3æ˜¯ä¸é”™çš„é€‰æ‹©ï¼Œå…¶ä¸­beam_num=1å³ä¸ºgreedy decodingã€‚

## 5. FAQ
#### é—®é¢˜1ï¼šOOMå¦‚ä½•è§£å†³ï¼Ÿ
å¦‚æœå‘ç”ŸOOMï¼Œå¯ä»¥ç¼©å°per GPU batch size (å¯åŠ¨è®­ç»ƒè„šæœ¬æ—¶çš„ç¬¬ä¸€ä¸ªå‚æ•°)ã€seq_lengthç­‰å‚æ•°æ¥ç¼“è§£ã€‚ä¹Ÿå¯ä»¥è®¾gradient_checkpointing=trueï¼Œå¯ä»¥å¤§å¹…é™ä½æ˜¾å­˜å ç”¨ï¼Œä½†è®­ç»ƒé€Ÿåº¦ä¼šå˜æ…¢ä¸€äº›ã€‚
