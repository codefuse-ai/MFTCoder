# MFTCoder: Accelerate + DeepSpeed/FSDP æ¡†æ¶ç¯‡
[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/codefuse-ai)
<a href="https://github.com/codefuse-ai/MFTCoder/blob/main/LICENSE">
    <img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue">
</a>

[**ä¸­æ–‡**] [[English]](README.md)

## 1. æ›´æ–°
ğŸ”¥ MFTCoder-accelerate æœ€æ–°æ”¯æŒçš„è®­ç»ƒæ¨¡å¼åŒ…æ‹¬: QLoRA/LoRA + DeepSpeed ZeRO2ï¼Œ QLoRA + DeepSpeed ZeRO3, å…¨é‡ + DeepSpeed ZeRO3, QLoRA + FSDP, å…¨é‡ + FSDPã€‚

ğŸ”¥ MFTCoder-accelerate æ–°å¢æ”¯æŒQLoRA + DeepSpeed ZeRO3ï¼Œ æ”¯æŒQLoRA + FSDP, å¯ä»¥è®­ç»ƒæ›´å¤§çš„æ¨¡å‹;

ğŸ”¥ MFTCoder-accelerate æ–°å¢æ”¯æŒaccelerate + FSDPæ¡†æ¶ï¼Œ æ”¯æŒå…¨é‡å¾®è°ƒå’ŒLoRA;

ğŸ”¥ MFTCoder-accelerate æ”¯æŒæœ€æ–°æ›´å¤šä¸»æµå¼€æºæ¨¡å‹: mistral, mixtral-8x7b(Mixture of Experts), deepseek, chatglm3ï¼›

ğŸ”¥ MFTCoder-accelerate æ–°å¢self-paced Loss, ç”¨äºæ”¶æ•›å‡è¡¡ï¼›

ğŸ”¥ MFTCoder-accelerate æ”¯æŒä½¿ç”¨accelerate + DeepSpeedæ¡†æ¶ä¸‹æ”¯æŒ å…¨é‡å‚æ•°/QLoRA/LoRAå¾®è°ƒï¼› 

ğŸ”¥ MFTCoder-accelerate åœ¨è®­ç»ƒä¸­æ”¯æŒäº†å¤šä»»åŠ¡å¾®è°ƒMFTï¼Œ å¯ä»¥åŒæ—¶å¹³è¡¡å¤šä¸ªä»»åŠ¡çš„è®­ç»ƒï¼Œè®­ç»ƒçš„æ¨¡å‹æ”¯æŒå¤šä»»åŠ¡æ¨ç†ï¼› 

ğŸ”¥ MFTCoder-accelerate åœ¨è®­ç»ƒä¸­æ”¯æŒå¤šç§æ¨¡å‹åŸºåº§ï¼š codellama, llama2, llama, starcoder, codegeex2, chatglm2, qwenç­‰

## 2. æ•°æ®æ ¼å¼
### 2.1 è®­ç»ƒæ•°æ®æ ¼å¼
è®­ç»ƒæ•°æ®ä¸ºjsonlæ ¼å¼ï¼Œæ¯ä¸€è¡Œçš„æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼Œå…¶ä¸­chat_roundså­—æ®µæ˜¯å¿…éœ€çš„ï¼Œå¯ä»¥æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ æˆ–åˆ é™¤å…¶ä»–å­—æ®µã€‚
å¯ä»¥å‚è€ƒé¡¹ç›®ä¸­çš„xxx.jsonlæ–‡ä»¶ã€‚
```json
{
    "id":0,
    "data_name":"code-helper",
    "chat_rounds":[
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»£ç åŠ©æ‰‹ï¼Œå¯ä»¥å›å¤ç”¨æˆ·ä¸ä»£ç ç›¸å…³çš„é—®é¢˜"
        },
        {
            "role": "human",
            "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åº"
        },
        {
            "role": "bot",
            "content": "ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•xxxxxx"
        },
        {
            "role": "human",
            "content": "è§£é‡Šä¸€ä¸‹è¿™æ®µä»£ç "
        },
        {
            "role": "bot",
            "content": "å¥½çš„ï¼Œè¿™æ®µä»£ç xxx"
        }
    ]
}
```

### 2.2 æ¨ç†æ•°æ®æ ¼å¼
æ¨ç†æ•°æ®æ ¼å¼ä¸ºæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®æ ¼å¼ä¸‹æ‹¼æ¥çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œå®ƒä¹Ÿæ˜¯æ¨ç†æ—¶è¾“å…¥promptæ‹¼æ¥çš„æ–¹å¼ï¼š
```
"""
<s>system
è¿™æ˜¯SystemæŒ‡ä»¤
<s>human
è¿™æ˜¯ç¬¬1è½®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
<s>bot
è¿™æ˜¯ç¬¬1è½®æ¨¡å‹ç”Ÿæˆçš„å†…å®¹{EOS_TOKEN}
<s>human
è¿™æ˜¯ç¬¬2è½®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
<s>bot
è¿™æ˜¯ç¬¬2è½®æ¨¡å‹ç”Ÿæˆçš„å†…å®¹{EOS_TOKEN}
...
...
...
<s>human
è¿™æ˜¯ç¬¬nè½®ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
<s>bot
{æ¨¡å‹ç°åœ¨è¦ç”Ÿæˆçš„å†…å®¹}{EOS_TOKEN}
"""
```


## 3. æ¨¡å‹è®­ç»ƒ
ç›®å‰æ”¯æŒå…¨é‡å‚æ•°(Full-parameters)æŒ‡ä»¤å¾®è°ƒã€QLoRAæŒ‡ä»¤å¾®è°ƒï¼ŒLoRAæŒ‡ä»¤å¾®è°ƒã€‚
ä¸€äº›ä¼˜ç§€çš„ä»£ç é¢„è®­ç»ƒæ¨¡å‹æƒé‡ï¼Œç†è®ºä¸Šï¼ŒHuggingFaceä¸Šå¼€æºçš„æ¨¡å‹ï¼Œå‡å¯ä½¿ç”¨æœ¬é¡¹ç›®è¿›è¡Œè®­ç»ƒï¼š

ğŸ¤— [æœ€æ–°ä»£ç é¢„è®­ç»ƒSOTAï¼ŒCodeLlama](https://huggingface.co/codellama/CodeLlama-34b-Python-hf) ï¼šcode-llama-34bï¼Œ code-llama-34b-python, æ–°çš„SOTAåŸºåº§ã€‚

ğŸ¤— [10Bçº§åˆ«æœ€ä½³ä»£ç é¢„è®­ç»ƒæ¨¡å‹Starcoder](https://huggingface.co/bigcode/starcoder) wizardCoder-15B, PanGu-coder2ç­‰å‰SOTAçš„åŸºåº§æ¨¡å‹ã€‚

ğŸ¤— [å¤šè¯­è¨€èƒ½æ‰‹Qwen-7b](https://huggingface.co/Qwen/Qwen-7B) ï¼šé€‚ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼Œä¹Ÿé€‚ç”¨ä¸­æ–‡ä»»åŠ¡ã€‚è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒæ—¶ã€‚

**mftcoder_accelerateæ–‡ä»¶ç»“æ„**
```
mftcoder_accelerate
       |
       src
          configs
          |
          data
          |
          model
          |
          *pefts*
          |
          tokenizer
          |
          utils
       |
       evals
```
æˆ‘ä»¬å°†è®­ç»ƒä¸­ä½¿ç”¨çš„å„ç§ç»„ä»¶æŠ½å–å‡ºæ¥ï¼Œä»¥ä¾¿åç»­çš„æ‰©å±•å’Œä¼˜åŒ–ï¼Œ è¯¦è§```src```ç›®å½•ä¸‹çš„å®ç°ã€‚

è®­ç»ƒå…¥å£æ–‡ä»¶æ˜¯```mftcoder_accelerate/src/pefts/mft_accelerate.py```

å‚æ•°é…ç½®å­˜å‚¨åœ¨```mftcoder_accelerate/src/configs```ç›®å½•ä¸‹ï¼Œæ–¹ä¾¿ç»Ÿä¸€ç®¡ç†å’Œæ›´æ”¹ã€‚

**_æ‰€ä»¥ï¼Œåœ¨ä½ å¼€å¯è®­ç»ƒä¹‹å‰ï¼Œè¯·è¿›å…¥srcç›®å½•_**
```
cd mftcoder_accelerate/src
```



### 3.1 æ•°æ®tokenization
è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†å¤šè½®å¯¹è¯æ‹¼æ¥æˆå¦‚ä¸‹æ ¼å¼ï¼ˆä¹Ÿæ˜¯ä¸Šæ–‡ä¸­çš„æ¨ç†æ•°æ®æ ¼å¼ï¼‰ï¼Œç„¶åè¿›è¡Œtokenizeã€‚
å…¶ä¸­ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼š

```<s>human\n```ä½œä¸ºhuman/userçš„èµ·å§‹ç¬¦ï¼Œ```<s>bot\n```ä½œä¸ºbot/assistantçš„èµ·å§‹ç¬¦ï¼Œ```{EOS_TOKEN}``` è¡¨ç¤ºeos_tokenã€‚
å…¶ä¸­eos_tokenå¯ä»¥æ ¹æ®ä¸åŒæ¨¡å‹ä¿®æ”¹æ›¿æ¢ã€‚ä¸åŒè§’è‰²çš„èµ·å§‹ç¬¦å¯ä»¥é…ç½®ï¼Œç”¨æ¥å®ç°ä¸åŒçš„å¯¹è¯/é—®ç­”æ¨¡ç‰ˆã€‚
```
"<s>human\n{input1}<s>bot\n{target1}{EOS_TOKEN}<s>human\n{input2}<s>bot\n{target2}{EOS_TOKEN}\n"
```
åœ¨è®¡ç®—lossæ—¶ï¼Œæˆ‘ä»¬é€šè¿‡loss maskçš„æ–¹å¼ï¼Œinputéƒ¨åˆ†çš„lossä¸å‚ä¸å‚æ•°æ›´æ–°ï¼Œåªæœ‰â€œtarget{EOS_TOKEN}â€éƒ¨åˆ†çš„losså‚ä¸å‚æ•°æ›´æ–°ã€‚
è¿™ç§æ–¹å¼å……åˆ†åˆ©ç”¨äº†æ¨¡å‹å¹¶è¡Œè®¡ç®—çš„ä¼˜åŠ¿ï¼Œè®­ç»ƒæ›´åŠ é«˜æ•ˆï¼ŒåŒæ—¶ä¹Ÿå……åˆ†åˆ©ç”¨äº†decoder-onlyæ¨¡å‹ä»å·¦åˆ°å³attentionçš„ç‰¹æ€§ï¼Œä¸€æ¬¡æ€§å°†å¤šè½®å¯¹è¯ä¸­çš„æ¯ä¸ªtargetéƒ¨åˆ†éƒ½å‚ä¸äº†è®­ç»ƒï¼Œè®­ç»ƒæ›´å……åˆ†é«˜æ•ˆã€‚

### 3.2 LoRA/QLoRAå¾®è°ƒ

#### LoRA/QLoRAå¾®è°ƒç®€ä»‹
å…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯å‚è€ƒè®ºæ–‡ï¼š[LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2106.09685.pdf)

å…³äºQLoRAçš„è¯¦ç»†ä»‹ç»å¯å‚è€ƒè®ºæ–‡ï¼š[QLORA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314.pdf)

QLoRAé€šè¿‡4-bitçš„nf4é‡åŒ–ï¼Œä¸”åŠ å…¥æ›´å¤šadapterï¼Œåœ¨å¤§å¹…å‡å°‘æ˜¾å­˜æ¶ˆè€—çš„åŒæ—¶ï¼Œå°½å¯èƒ½é€¼è¿‘å…¨é‡å‚æ•°å¾®è°ƒçš„æ•ˆæœã€‚
QLoRAè®ºæ–‡æŒ‡å‡ºï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨ä¸€å¼ V100ä¸Šå¯¹33Bçš„æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”æ€§èƒ½é€¼è¿‘å…¨é‡å‚æ•°å¾®è°ƒã€‚

æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯è¿›è¡Œ Lora/QLora/å…¨é‡ å¾®è°ƒï¼š
#### Deepspeed å•æœºå¯åŠ¨
DeepSpeedé…ç½®åœ¨accelerate_ds_config.yamlä¸­ã€‚
```bash
accelerate launch --config_file accelerate_ds_config.yaml pefts/mft_accelerate.py --train_config configs/xxx_train_config.json --distributed_type "DeepSpeed" 
```
æˆ–è€…

DeepSpeed Zero2 é…ç½®åœ¨è„šæœ¬ä¸­é€šè¿‡å‘½ä»¤è¡Œè¾“å…¥ã€‚
```bash
sh ds_single_launch.sh
```

DeepSpeed Zero3 é…ç½®åœ¨è„šæœ¬ä¸­é€šè¿‡å‘½ä»¤è¡Œè¾“å…¥
```bash
sh ds_zero3_single_launch.sh
```

#### FSDP å•æœºå¯åŠ¨
FSDPé…ç½®åœ¨accelerate_fsdp_config.yamlä¸­ã€‚
```bash
accelerate launch --config_file accelerate_fsdp_config.yaml pefts/mft_accelerate.py --train_config configs/xxx_train_config.json --distributed_type "FSDP"
```
æˆ–è€…

FSDPé…ç½®åœ¨è„šæœ¬ä¸­é€šè¿‡å‘½ä»¤è¡Œè¾“å…¥ã€‚
```bash
sh fsdp_single_launch.sh
```

#### å¤šæœºå¯åŠ¨
å¤šæœºå¯åŠ¨è¯·å‚è€ƒå¦‚ä¸‹deepspeedå¤šæœºå¯åŠ¨è„šæœ¬
```bash
sh ds_multinode_launch.sh
```

#### è®­ç»ƒå‚æ•°
_**è®­ç»ƒéœ€è¦çš„å‚æ•°é…ç½®åœ¨```configs/*_train_config```ä¸­ï¼Œä¸»è¦å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š**_

- **load_raw_dataset**: éœ€è¦ä¿æŒtrueï¼Œåç»­ä¼šæ”¯æŒå…¶å®ƒæ¨¡å¼æ•°æ®ï¼Œå½“å‰ä»…æ”¯æŒjsonlè¾“å…¥
- **data_paths**: "[path1,path2,path3]" è¾“å…¥æ•°æ®åœ°å€ï¼Œå­—ç¬¦ä¸²ï¼Œå¼€å¤´ç»“å°¾ç”¨[]ï¼Œä¸­é—´ç”¨```,```é—´éš”ä¸åŒpathï¼Œæ¯ä¸ªpathæ˜¯ä¸€ä¸ªç›®å½•ï¼Œç›®å½•çš„æœ€åä¸€çº§åå­—ä½œä¸ºä»»åŠ¡åç§°ï¼Œä¸‹é¢åŒ…å«1åˆ°å¤šä¸ªjsonlæ•°æ®
- **output_dir**ï¼šè®­ç»ƒè¾“å‡ºç›®å½•ï¼Œå­˜å‚¨checkpoint(å…¨é‡è®­ç»ƒæ—¶)ã€lora_adaptorï¼ˆLoraæˆ–è€…Qloraæ—¶ï¼‰ç­‰
- **tb_dir**: å­˜å‚¨tensorboardç­‰
- **model_type**: "mixtral|mistral|deepseek|llama|starcoder|chatglm2|qwen|gpt_neox"
- **attn_implementation**: "flash_attention_2" æˆ–è€… "eager"
- **peft_type**: loraæˆ–è€…qloraæˆ–è€…null(å…¨é‡å¾®è°ƒ)
- **lora_rank**: lora rank
- **lora_alpha**: lora alpha
- **lora_dropout**: lora dropout
- **target_modules**: List[str], loraç›®æ ‡æ¨¡å—ï¼Œå¦‚æœnullï¼Œä¼šä½¿ç”¨é»˜è®¤ï¼Œå‚è€ƒmodel_mapping.py
- **quantization**: æ˜¯å¦é‡åŒ–ï¼Œ"4bit", "8bit" æˆ–è€…nullï¼Œ qloraæ¨è4bité‡åŒ–
- **pretrained_model_path**ï¼šé¢„è®­ç»ƒæ¨¡å‹çš„æœ¬åœ°ç›®å½•ï¼Œæˆ–è€…åœ¨huggingfaceä¸Šçš„æ¨¡å‹åç§°ã€‚
- **weighted_loss_mode**: å¤šä»»åŠ¡lossåŠ æƒæ¨¡å¼ï¼Œ "case3"æ˜¯å½“å‰æ¨èã€‚
- **padding_mode**: æ•°æ®çš„æ ·æœ¬ç»„ç»‡æ–¹å¼ï¼Œ "padding"æ˜¯å°†æ¯ä¸ªåŸå§‹æ ·æœ¬å¡«å……åˆ°seq_length, "pack"æ˜¯å°†å°½é‡å¤šçš„æ ·æœ¬æ‰“åŒ…åˆ°æ¯ä¸ªseq_lengthçš„åºåˆ—ä¸­ã€‚
- **num_train_epochs**ï¼šè®­ç»ƒçš„è½®æ¬¡ã€‚å¦‚æœæ•°æ®é‡è¶³å¤Ÿå¤§ï¼Œä¸€èˆ¬å»ºè®®åªè®­1-2ä¸ªepochã€‚
- **per_device_train_batch_size**ï¼šæ¯å¼ æ˜¾å¡trainçš„batch sizeã€‚
- **per_device_eval_batch_size**ï¼šæ¯å¼ æ˜¾å¡evalçš„batch sizeã€‚
- **gradient_accumulation_steps**ï¼šæ¢¯åº¦ç´¯è®¡æ­¥æ•°ã€‚global batch=num_gpus * per_device_train_batch_size * gradient_accumulation_stepsã€‚
- **learning_rate**ï¼šå­¦ä¹ ç‡ã€‚å…¨é‡å‚æ•°å¾®è°ƒçš„æ—¶å€™ï¼Œå»ºè®®å°ä¸€äº›ï¼Œ1e-5æˆ–5e-6ã€‚qloraä¸­çš„å­¦ä¹ ç‡è®¾ç½®æ›´å¤§ä¸€äº›ï¼Œä¸€èˆ¬ä¸º1e-4ã€2e-4ã€‚
- **min_lr**: æœ€ä½å­¦ä¹ ç‡ï¼Œ ä¸€èˆ¬æ˜¯learning_rateçš„ååˆ†ä¹‹ä¸€
- **seq_length**ï¼šè®­ç»ƒæ—¶çš„æœ€å¤§é•¿åº¦ã€‚æŒ‰ç…§è‡ªå·±çš„è®¾å¤‡è¿›è¡Œè®¾ç½®ï¼Œè¶Šé•¿éœ€è¦å ç”¨è¶Šå¤šæ˜¾å­˜ã€‚
- **log_interval**ï¼šæ¯éš”å¤šå°‘æ­¥ç»Ÿè®¡ä¸€æ¬¡train lossã€‚
- **checkpointing_steps**ï¼šæ¯éš”å¤šå°‘æ­¥ä¿å­˜ä¸€ä¸ªæ¨¡å‹ã€‚
- **evaluation_steps**ï¼šæ¯éš”å¤šå°‘æ­¥åœ¨éªŒè¯é›†ä¸Ševaluateä¸€æ¬¡ã€‚
- **early_stopping** ï¼š æ˜¯å¦æ‰§è¡Œearly_stop
- **early_stopping_stall_num**ï¼š å¤šå°‘ä¸ªeval pointä¸ç»§ç»­æ”¶æ•›ï¼Œåˆ™åœæ­¢è®­ç»ƒ
- **lr_scheduler_type**ï¼šå­¦ä¹ ç‡å˜åŒ–ç­–ç•¥ã€‚å¸¸ç”¨"cosine"
- **warmup_steps**ï¼šwarm upæ­¥æ•°ã€‚å­¦ä¹ ç‡ç»è¿‡å¤šå°‘æ­¥ï¼Œå¢é•¿åˆ°æŒ‡å®šçš„æ•°å€¼ã€‚
- **seed**ï¼šéšæœºç§å­ï¼Œç”¨äºå¤ç°å®éªŒç»“æœã€‚
- **saving_limit**ï¼šæ•´æ•°ï¼Œckptå­˜å‚¨æ•°é‡ä¸Šé™ï¼Œ å…¨é‡è®­ç»ƒå¿…é¡»è®¾ç½®ã€‚é»˜è®¤nullå³ä¸é™åˆ¶æ•°é‡ã€‚
- **role_markers**: nullï¼Œå³ä½¿ç”¨{"system": "\<s\>system\n", "user": "\<s\>human\n", "assistant": "\<s\>bot\n"}ã€‚ ä½ å¯ä»¥è‡ªå®šä¹‰ "system", "user" and "assistant"çš„æ¨¡æ¿ï¼Œ ç”¨äºå®šåˆ¶è‡ªå·±çš„é—®ç­”æˆ–è€…å¯¹è¯æ¨¡æ¿ï¼Œæ¯”å¦‚ {"system": "### System:\n", "user": "### Instruction:\n", "assistant": "### Response:\n"}

## 4. æ¨¡å‹ä½¿ç”¨

### 4.1 æƒé‡åˆå¹¶
å¦‚æœä½¿ç”¨LoRAæˆ–è€…QLoRAè¿›è¡Œè®­ç»ƒï¼Œæœ¬é¡¹ç›®ä»…ä¿å­˜adapterçš„æƒé‡å’Œé…ç½®æ–‡ä»¶ï¼Œéœ€è¦å°†adapteræƒé‡ä¸base modelè¿›è¡Œåˆå¹¶ã€‚
å¯ä»¥ä½¿ç”¨å¦‚ä¸‹merge_base_and_lora_to_hf.pyè„šæœ¬ã€‚
```
python pefts/merge_base_and_lora_to_hf.py \
    --base_model_or_path model_path \
    --adaptor_path lora_adapter_path \
    --model_type model_type \
    --merged_output_path output_path
```

### 4.2 æ¨¡å‹æ¨ç†
æˆ‘ä»¬æä¾›äº†å•è½®å¯¹è¯å’Œå¤šè½®å¯¹è¯çš„å¦‚ä¸‹è„šæœ¬ï¼Œè¯¥è„šæœ¬å¯åŒæ—¶å…¼å®¹å¤§éƒ¨åˆ†huggingfaceæ ¼å¼çš„æ¨¡å‹ã€‚
```python
from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM,
)
model_name_or_path = "codefuse-ai/CodeFuse-Deepseek-33B"
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, padding_side="left")
tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids("<ï½œendâ–ofâ–sentenceï½œ>")
tokenizer.pad_token_id = tokenizer.eos_token_id
model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True)

HUMAN_ROLE_START_TAG = "<s>human\n"
BOT_ROLE_START_TAG = "<s>bot\n"
texts = ["write a python function of quick sort."]
texts = [f"{HUMAN_ROLE_START_TAG}{text}{BOT_ROLE_START_TAG}" for text in texts]

inputs = tokenizer(texts, return_tensors='pt', padding=True, add_special_tokens=False).to("cuda")
outputs = model.generate(
        inputs=inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        max_new_tokens=512,
        top_p=0.95,
        temperature=0.1,
        do_sample=True,
        eos_token_id=tokenizer.eos_token_id,
        pad_token_id=tokenizer.pad_token_id
    )
gen_text = tokenizer.batch_decode(outputs[:, inputs["input_ids"].shape[1]:], skip_special_tokens=True)
print(gen_text)
```


ç”Ÿæˆè„šæœ¬ä¸­çš„top_pã€temperatureã€repetition_penaltyã€do_sampleç­‰å‚æ•°å¯¹æ¨¡å‹çš„ç”Ÿæˆæ•ˆæœå½±å“è¾ƒå¤§ï¼Œå¯æŒ‰ç…§è‡ªå·±çš„ä½¿ç”¨åœºæ™¯è¿›è¡Œè°ƒè¯•ä¿®æ”¹ã€‚
å®è·µä¸­ï¼Œåœ¨ä»£ç ç”Ÿæˆåœºæ™¯ä¸­ï¼Œå¦‚æœé‡‡æ ·æ¨¡å¼ï¼Œdo_sample=True, top_p=0.95, temperature=0.1æ˜¯pass@1æŒ‡æ ‡çš„ä¸é”™é€‰æ‹©ï¼›
å¦‚æœéé‡‡æ ·æ¨¡å¼ï¼Œ do_sample=False, beam_num=1æˆ–è€…3æ˜¯ä¸é”™çš„é€‰æ‹©ï¼Œå…¶ä¸­beam_num=1å³ä¸ºgreedy decodingã€‚

## 5. FAQ
#### é—®é¢˜1ï¼šOOMå¦‚ä½•è§£å†³ï¼Ÿ
å¦‚æœå‘ç”ŸOOMï¼Œå¯ä»¥ç¼©å°per_device_train_batch_sizeã€seq_lengthç­‰å‚æ•°æ¥ç¼“è§£ã€‚ç”±äºé¢å¯¹çš„æ¨¡å‹æ™®éè¾ƒå¤§ï¼ˆ6bï¼Œ 13bï¼Œ 34bï¼Œ 70bç­‰ï¼‰æˆ‘ä»¬å·²ç»é»˜è®¤ä½¿ç”¨gradient_checkpointingæŠ€æœ¯ï¼Œå¯ä»¥å¤§å¹…é™ä½æ˜¾å­˜å ç”¨ï¼Œä½†è®­ç»ƒé€Ÿåº¦ä¼šç¨æ…¢ä¸€äº›ã€‚
å¦‚æœæ˜¯æ¨¡å‹å¤ªå¤§ï¼Œå¯ä»¥ä½¿ç”¨QLoRA + DeepSpeed ZeRO3(é…ç½® zero stage = 3)ï¼Œè¿™ä¸ªæ–¹æ¡ˆå¯ä»¥åœ¨å¡æ•°è¶³å¤Ÿçš„æƒ…å†µä¸‹ï¼Œå¾®è°ƒæ›´å¤§çš„æ¨¡å‹ã€‚
#### é—®é¢˜2ï¼šå®‰è£…åŒ…é”™è¯¯
å‚è€ƒinit_env.shå’Œrequirements.txt

#### é—®é¢˜3ï¼šå¦‚ä½•æŒ‡å®šä½¿ç”¨æŸäº›å¡è®­ç»ƒï¼Ÿ
é€šè¿‡å¦‚ä¸‹æ–¹å¼ï¼Œå³å¯æŒ‡å®šä½¿ç”¨0å’Œ1å·å¡è¿›è¡Œè®­ç»ƒ:
```bash
CUDA_VISIBLE_DEVICES=0,1 accelerate launch --config_file pefts/accelerate_ds_config.yaml pefts/mft_accelerate.py --train_config configs/xxx_train_config.json --distributed_type "deepspeed"
```

#### é—®é¢˜4ï¼šå…³äºFlash Attention, è¯¥å¦‚ä½•é…ç½®è®­ç»ƒï¼Ÿ
é¦–å…ˆï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨å®‰è£…Flash Attention 2(FA2)ï¼Œï¼ˆ>=2.1.0, 2.3.6åŠŸèƒ½æ›´é½å…¨ï¼‰ã€‚

è®­ç»ƒå‚æ•°ä¸­"attn_implementation" è®¾ç½®æˆ "eager" å¯ä»¥ç”¨naive attentionï¼Œä¹Ÿå°±æ˜¯æœªç»åŠ é€Ÿçš„attentionã€‚

è®­ç»ƒå‚æ•°ä¸­"attn_implementation" è®¾ç½®æˆ "flash_attention_2" å¯ä»¥ç”¨FA2ï¼Œé€Ÿåº¦å¿«ï¼Œçœæ˜¾å­˜ã€‚

å¦‚æœä½ å¯ä»¥è‡ªè¡Œå®‰è£…ç¯å¢ƒå¹¶ä½¿ç”¨torch>=2.1.1ï¼Œå¯ä»¥å°è¯•è®¾ç½®å‚æ•°"attn_implementation"ä¸º "sdpa"ã€‚è¿™æ ·ä¼šå°è¯•ä½¿ç”¨transformerså…¼å®¹çš„torch.nn.functional.scaled_dot_product_attentionã€‚æ”¯æŒçš„æ¨¡å‹è¿˜ä¸å…¨é¢ã€‚

#### é—®é¢˜5ï¼šæ¨èçš„åˆ†å¸ƒå¼æ¡†æ¶æ˜¯æ€æ ·çš„ï¼Ÿ
å¯¹äºLoRA, æˆ‘ä»¬æ¨èä½¿ç”¨DeepSpeed Zero2ä½œä¸ºåº•å±‚åˆ†å¸ƒå¼æ¡†æ¶ï¼Œå®ƒå…·æœ‰æ˜“ç”¨æ€§å’Œå…¼å®¹æ€§å¥½çš„ç‰¹ç‚¹ï¼Œå¹¶ä¸”é€Ÿåº¦å¾ˆå¿«, æ¨¡å‹åŠ è½½æ¨¡å¼ä¸Šç±»ä¼¼DDPã€‚
å¯¹äºQLoRA, DeepSpeed Zero2 é€‚åˆä¸­å°æ¨¡å‹, DeepSpeed Zero3 é€‚åˆå¾ˆå¤§çš„æ¨¡å‹ã€‚

å¯¹äºå…¨é‡å¾®è°ƒï¼Œå¯ä»¥ä½¿ç”¨DeepSpeed Zero3, æˆ–è€…FSDPã€‚äºŒè€…éƒ½æ˜¯Fully Shardingæ¨¡å¼ï¼Œå³æ¨¡å‹åŠ è½½å¹³åˆ†åœ¨æ¯å¼ å¡ã€‚

#### é—®é¢˜6ï¼šå½“å‰æ”¯æŒçš„æ¨¡å‹ä¸­ï¼Œæœ‰ä»€ä¹ˆåŒºåˆ«
å›½äº§å¤§æ¨¡å‹æ¯”å¦‚chatglm2ï¼Œ chatglm3ï¼Œ baichuan2ï¼Œ qwenï¼Œ aquila2ç­‰ï¼Œä½¿ç”¨çš„æ˜¯å’Œæ¨¡å‹å…±åŒå‘å¸ƒçš„modeling_xxx.py. 
å…¶å®ƒè¢«transformerså®˜æ–¹æ”¯æŒçš„å¤§æ¨¡å‹ï¼Œæ¯”å¦‚llama, qwen2, starcoder2, mistralç­‰ï¼Œå…¨é¢åˆ‡æ¢åˆ°å®˜æ–¹çš„modelingæ”¯æŒè®­ç»ƒï¼Œä¹‹å‰çš„è‡ªå®šä¹‰modelingä¼šè¢«deprecatedã€‚





